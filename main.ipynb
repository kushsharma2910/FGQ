{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushsharma2910/FGQ/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Ofmk-G-Nk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8c285677-7e82-43c1-cbf9-ff5eb352bb35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32BpqMho9hU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDjFHyaS9hVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################################################\n",
        "################################# CREATING LARGEDF  ###################################\n",
        "#######################################################################################\n",
        "\n",
        "def change_index_to_time(df):\n",
        "    if \"Time (UTC)\" in df.columns:\n",
        "      df['Time (UTC)'] = pd.to_datetime(df['Time (UTC)'])\n",
        "      df.set_index('Time (UTC)', inplace = True, drop = True)\n",
        "    \n",
        "#Finds the dataframe with largest number of time stamps and returns an empty dataframe with same index\n",
        "def create_empty_df(dir_name):\n",
        "    largest_timeframe = 0\n",
        "    path_to_largest = \"\"\n",
        "\n",
        "    for asset_class in os.listdir(dir_name):\n",
        "        for asset in os.listdir(dir_name +  \"/\" + asset_class):    \n",
        "            df = pd.read_csv(dir_name +  \"/\" + asset_class + \"/\" + asset)\n",
        "            if df.shape[0] > largest_timeframe:\n",
        "                largest_timeframe = df.shape[0]\n",
        "                path_to_largest = dir_name +  \"/\" + asset_class + \"/\" + asset\n",
        "\n",
        "    largest_dataframe = pd.read_csv(path_to_largest)\n",
        "    change_index_to_time(largest_dataframe)\n",
        "    largest_dataframe = pd.DataFrame(index = largest_dataframe.index)\n",
        "    return largest_dataframe\n",
        "\n",
        "#######################################################################################\n",
        "################################# FEATURE BUILDING  ###################################\n",
        "#######################################################################################\n",
        "\n",
        "def trim_fft(df):\n",
        "    all_fft = []\n",
        "    for column in df.columns:\n",
        "        if \"fft\" in column:\n",
        "            all_fft.append(column)\n",
        "    df = df.drop(columns = all_fft)\n",
        "    return df\n",
        "\n",
        "def fill_large_df(dir_name, large_df):\n",
        "    asset67 = []\n",
        "    for asset_class in os.listdir(dir_name):\n",
        "        for asset in os.listdir(dir_name +  \"/\" + asset_class): \n",
        "            extract_name = asset.split(\"_\")\n",
        "            asset67.append(extract_name[0][:-4])\n",
        "            df = pd.read_csv(dir_name +  \"/\" + asset_class + \"/\" + asset)\n",
        "            change_index_to_time(df)\n",
        "            df = trim_fft(df)\n",
        "            large_df = large_df.join(df)\n",
        "            rename_dic = {}\n",
        "            for column in df.columns:    \n",
        "                rename_dic[column] = column + \"@\" + extract_name[0][:-4]\n",
        "            large_df = large_df.rename(columns = rename_dic) \n",
        "            \n",
        "    return large_df, asset67\n",
        "\n",
        "def add_lag_features(only_feat_df):\n",
        "  lag_feat = only_feat_df.copy()\n",
        "  BASE_FEATURES = [\"Open@\" + target_asset, \"High@\" + target_asset, \"Low@\" + target_asset, \"Close@\" + target_asset]\n",
        "  N_WINDOW = [4, 24, 128, 256]\n",
        "  prevlag = 1 \n",
        "  for window in N_WINDOW:\n",
        "    rolled = lag_feat[BASE_FEATURES].shift(prevlag).rolling(window=window)\n",
        "    lag_feat = lag_feat.join(rolled.mean().add_suffix(f'_window_{window}_mean'))\n",
        "    lag_feat = lag_feat.join(rolled.max().add_suffix(f'_window_{window}_max'))\n",
        "    lag_feat = lag_feat.join(rolled.min().add_suffix(f'_window_{window}_min'))\n",
        "    lag_feat = lag_feat.join(rolled.std().add_suffix(f'_window_{window}_std'))\n",
        "  return lag_feat\n",
        "\n",
        "def extract_features(large_df, target_asset, target_window, asset67, add_lag = False):\n",
        "    df = large_df.copy()\n",
        "\n",
        "    #comment out this line if you \n",
        "    #don't want to use the lag features\n",
        "    if add_lag:\n",
        "      df = add_lag_features(df)\n",
        "\n",
        "    df[\"H-\" + str(target_window) + \"hr\" ] = df.pop(\"H-\" + str(target_window) + \"hr@\" + target_asset)\n",
        "    df[\"L-\" + str(target_window) + \"hr\" ] = df.pop(\"L-\" + str(target_window) + \"hr@\" + target_asset)\n",
        "    \n",
        "    #removing targets of assets other\n",
        "    # than the target assset\n",
        "    for asset in asset67:\n",
        "        if asset != target_asset:\n",
        "            df = df.drop(columns = [\"H-4hr@\" + asset, \"L-4hr@\" + asset, \"H-12hr@\" + asset,\n",
        "                               \"L-12hr@\" + asset, \"H-24hr@\" + asset,\"L-24hr@\" + asset])\n",
        "            \n",
        "    #this loop asserts that labels for target asset is\n",
        "    #not present for other windows\n",
        "    windows = [\"4\", \"12\", \"24\"]\n",
        "    for window in windows:\n",
        "      if window != str(target_window):\n",
        "        high = \"H-\" + window + \"hr@\" + target_asset\n",
        "        low = \"L-\" + window + \"hr@\" + target_asset\n",
        "        if high in df.columns:\n",
        "          df = df.drop(columns = [high])\n",
        "        if low in df.columns:\n",
        "          df = df.drop(columns = [low])\n",
        "    \n",
        "    change_index_to_time(df)        \n",
        "    return df\n",
        "\n",
        "#######################################################################################\n",
        "################################# MODEL BUILDING  #####################################\n",
        "#######################################################################################\n",
        "\n",
        "\n",
        "#predicting the H as previous value\n",
        "def create_baseline(only_feat_df, direction, target_window):     \n",
        "    preds = np.array(pd.Series(only_feat_df[direction + \"-\" + str(target_window) + \"hr\"]).shift(1).bfill(axis = 0))\n",
        "    actual = np.array(only_feat_df[direction + \"-\" + str(target_window) + \"hr\"])\n",
        "    return preds, actual\n",
        "\n",
        "#######################################################################################\n",
        "############################# ACCURACY CALCULATIONS  ##################################\n",
        "#######################################################################################\n",
        "\n",
        "def acc_abs(preds, actual, tolerance):\n",
        "    tolerance /= 100\n",
        "    return np.sum(np.abs(preds/actual-1) <= tolerance)\n",
        "\n",
        "def acc_dir(preds, actual, tolerance, direction):\n",
        "    tolerance /= 100\n",
        "    score = 0\n",
        "    for ix in range(preds.shape[0]):\n",
        "        if actual[ix] > preds[ix]*(1+tolerance)  and direction == \"H\":\n",
        "            score += 1\n",
        "        elif actual[ix] < preds[ix]*(1-tolerance)  and direction == \"L\":\n",
        "             score += 1\n",
        "    return score\n",
        "\n",
        "def min_pips(preds, actual, opens, tolerance, pips, direction):\n",
        "    pips /= 100\n",
        "    tolerance /= 100\n",
        "    score = 0\n",
        "    for ix in range(preds.shape[0]):\n",
        "        if preds[ix] < actual[ix]*(1+tolerance)  and (direction == \"H\" and (actual[ix] - opens[ix])>=pips):\n",
        "            score += 1 \n",
        "        elif preds[ix] > actual[ix]*(1+tolerance)  and (direction == \"L\" and (opens[ix] - actual[ix])>=pips):\n",
        "             score += 1\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ox-Y7o39hVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#name of the root directory which contains asset classes which further contain asset csv ask and bid pairs\n",
        "# dir_name = \"Data\"\n",
        "# large_df = create_empty_df(dir_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL0w8A809hVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#asset67 contains the 67 selected assets which have data for more than 6 years\n",
        "# large_df_, asset67 = fill_large_df(dir_name, large_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lGdKz6O9hVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filling in previous values for values in middle\n",
        "# large_df_ = large_df_.ffill(axis=0)\n",
        "\n",
        "#Filling in next value for initial nan values\n",
        "#This is used for assets which do not have initial data\n",
        "# large_df_ = large_df_.bfill(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vztj-_QJ_Kah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "94320aab-0d31-42ef-982e-e0643d2399aa"
      },
      "source": [
        "#to extract to a given path\n",
        "# import zipfile\n",
        "# with zipfile.ZipFile(\"drive/My Drive/large_df_.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"drive/My Drive/\")\n",
        "\n",
        "#to extract to the home dir\n",
        "!unzip \"drive/My Drive/large_df_.zip\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/large_df_.zip\n",
            "  inflating: large_df_.csv           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVeRVJ1SCbm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#When using google drive\n",
        "large_df_ = pd.read_csv(\"large_df_.csv\")\n",
        "\n",
        "#List of assets present\n",
        "#in large_df_\n",
        "asset67 = np.array(pd.read_csv(\"drive/My Drive/asset67.csv\").iloc[:, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDBBD8Sn9hVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input variables\n",
        "target_asset = \"XAGUSD\"\n",
        "target_window = 12\n",
        "direction = \"L\"\n",
        "#give tolerance in percent\n",
        "tolerance = 0.04\n",
        "\n",
        "only_feat_df = extract_features(large_df_, target_asset, target_window, asset67, add_lag=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q93nvpzN9hVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#in the xlsx file, first row and columns have been removed for efficient reading\n",
        "pip_xl = pd.read_excel(\"drive/My Drive/Labels to Forecast.xlsx\")\n",
        "\n",
        "#querying pips\n",
        "pips = pip_xl[pip_xl[\"Label\"] == target_asset][str(target_window) + \" Hour\"].values[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57UvZ4hIqzXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "469715cb-b079-4f28-8546-5f68cab57ed4"
      },
      "source": [
        "preds, actual = create_baseline(only_feat_df, direction, target_window)\n",
        "\n",
        "#calculate accuracies\n",
        "print(acc_abs(preds, actual, tolerance))\n",
        "print(acc_dir(preds, actual, tolerance, direction))\n",
        "print(min_pips(preds, actual, only_feat_df[\"Open@\" + target_asset], tolerance, pips, direction))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105908\n",
            "7871\n",
            "999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA2iL8KQkUJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}